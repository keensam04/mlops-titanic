apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.22, pipelines.kubeflow.org/pipeline_compilation_time: '2025-02-17T23:21:05.119787',
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "mybucket", "name":
      "bucket", "optional": true, "type": "String"}, {"default": "param.json", "name":
      "param_path", "optional": true, "type": "String"}, {"default": "train.csv",
      "name": "train_path", "optional": true, "type": "String"}, {"default": "test.csv",
      "name": "test_path", "optional": true, "type": "String"}, {"default": "train.pickle",
      "name": "processed_train_path", "optional": true, "type": "String"}, {"default":
      "model.json", "name": "model_path", "optional": true, "type": "String"}], "name":
      "Pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.22}
spec:
  entrypoint: pipeline
  templates:
  - name: exit-handler-1
    inputs:
      parameters:
      - {name: bucket}
      - {name: model_path}
      - {name: param_path}
      - {name: processed_train_path}
      - {name: test_path}
      - {name: train_path}
    dag:
      tasks:
      - name: preprocessing
        template: preprocessing
        dependencies: [seed]
        arguments:
          parameters:
          - {name: bucket, value: '{{inputs.parameters.bucket}}'}
          - {name: processed_train_path, value: '{{inputs.parameters.processed_train_path}}'}
          - {name: test_path, value: '{{inputs.parameters.test_path}}'}
          - {name: train_path, value: '{{inputs.parameters.train_path}}'}
      - name: seed
        template: seed
        dependencies: [status-op-2]
        arguments:
          parameters:
          - {name: bucket, value: '{{inputs.parameters.bucket}}'}
          - {name: param_path, value: '{{inputs.parameters.param_path}}'}
          - {name: test_path, value: '{{inputs.parameters.test_path}}'}
          - {name: train_path, value: '{{inputs.parameters.train_path}}'}
      - {name: status-op-2, template: status-op-2}
      - name: train
        template: train
        dependencies: [preprocessing]
        arguments:
          parameters:
          - {name: bucket, value: '{{inputs.parameters.bucket}}'}
          - {name: model_path, value: '{{inputs.parameters.model_path}}'}
          - {name: param_path, value: '{{inputs.parameters.param_path}}'}
          - {name: processed_train_path, value: '{{inputs.parameters.processed_train_path}}'}
  - name: pipeline
    inputs:
      parameters:
      - {name: bucket}
      - {name: model_path}
      - {name: param_path}
      - {name: processed_train_path}
      - {name: test_path}
      - {name: train_path}
    dag:
      tasks:
      - name: exit-handler-1
        template: exit-handler-1
        arguments:
          parameters:
          - {name: bucket, value: '{{inputs.parameters.bucket}}'}
          - {name: model_path, value: '{{inputs.parameters.model_path}}'}
          - {name: param_path, value: '{{inputs.parameters.param_path}}'}
          - {name: processed_train_path, value: '{{inputs.parameters.processed_train_path}}'}
          - {name: test_path, value: '{{inputs.parameters.test_path}}'}
          - {name: train_path, value: '{{inputs.parameters.train_path}}'}
  - name: preprocessing
    container:
      args: []
      command: [python, pre_processing.py, --bucket, '{{inputs.parameters.bucket}}',
        --train-path, '{{inputs.parameters.train_path}}', --test-path, '{{inputs.parameters.test_path}}',
        --processed-train-path, '{{inputs.parameters.processed_train_path}}']
      image: mlops-titanic/pipeline/components/preprocessing:1.0
    inputs:
      parameters:
      - {name: bucket}
      - {name: processed_train_path}
      - {name: test_path}
      - {name: train_path}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Prepares
          data for training.\n", "implementation": {"container": {"command": ["python",
          "pre_processing.py", "--bucket", {"inputValue": "bucket"}, "--train-path",
          {"inputValue": "train_path"}, "--test-path", {"inputValue": "test_path"},
          "--processed-train-path", {"inputValue": "processed_train_path"}], "image":
          "mlops-titanic/pipeline/components/preprocessing:1.0"}}, "inputs": [{"description":
          "The S3 bucket to store results.", "name": "bucket", "type": "String"},
          {"description": "The s3 path of the training data.", "name": "train_path",
          "type": "String"}, {"description": "The s3 path of the test data.", "name":
          "test_path", "type": "String"}, {"description": "The s3 path to dump the
          processed training data.", "name": "processed_train_path", "type": "String"}],
          "name": "PreProcessing"}', pipelines.kubeflow.org/component_ref: '{"digest":
          "3127b0b6723a3a73c6dee68c1b4f901471a4a6e7782a45b9ee48f37dd79971c7", "url":
          "pipeline/components/pre-processing/pre-processing.yaml"}', pipelines.kubeflow.org/arguments.parameters: '{"bucket":
          "{{inputs.parameters.bucket}}", "processed_train_path": "{{inputs.parameters.processed_train_path}}",
          "test_path": "{{inputs.parameters.test_path}}", "train_path": "{{inputs.parameters.train_path}}"}'}
  - name: seed
    container:
      args: []
      command: [python, seed.py, --bucket, '{{inputs.parameters.bucket}}', --param-path,
        '{{inputs.parameters.param_path}}', --train-path, '{{inputs.parameters.train_path}}',
        --test-path, '{{inputs.parameters.test_path}}']
      image: mlops-titanic/pipeline/components/seed:1.0
    inputs:
      parameters:
      - {name: bucket}
      - {name: param_path}
      - {name: test_path}
      - {name: train_path}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Seeds
          an S3 bucket with data and config.\n", "implementation": {"container": {"command":
          ["python", "seed.py", "--bucket", {"inputValue": "bucket"}, "--param-path",
          {"inputValue": "param_path"}, "--train-path", {"inputValue": "train_path"},
          "--test-path", {"inputValue": "test_path"}], "image": "mlops-titanic/pipeline/components/seed:1.0"}},
          "inputs": [{"description": "The S3 bucket to store results.", "name": "bucket",
          "type": "String"}, {"description": "The s3 path to dump training param file.",
          "name": "param_path", "type": "String"}, {"description": "The s3 path to
          dump training data.", "name": "train_path", "type": "String"}, {"description":
          "The s3 path to dump test data.", "name": "test_path", "type": "String"}],
          "name": "Seed"}', pipelines.kubeflow.org/component_ref: '{"digest": "fecd0ed06be232ff186e016b56369ceedc6c2580fcec93cffb2d5bc4d03f8c4a",
          "url": "pipeline/components/seed/seed.yaml"}', pipelines.kubeflow.org/arguments.parameters: '{"bucket":
          "{{inputs.parameters.bucket}}", "param_path": "{{inputs.parameters.param_path}}",
          "test_path": "{{inputs.parameters.test_path}}", "train_path": "{{inputs.parameters.train_path}}"}'}
  - name: status-op
    container:
      args: [--name, '{{workflow.name}}', --status, '{{workflow.status}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def status_op(name, status):
            """Dummy method to send pipeline status to the configured channel.
            In this example, it's STDOUT. In practice, it is usually a notification to Slack or email etc"""
            print(f"workflow={name} status={status}")

        import argparse
        _parser = argparse.ArgumentParser(prog='Status op', description='Dummy method to send pipeline status to the configured channel.')
        _parser.add_argument("--name", dest="name", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--status", dest="status", type=str, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = status_op(**_parsed_args)
      image: python:3.10-slim-bullseye
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Dummy
          method to send pipeline status to the configured channel.", "implementation":
          {"container": {"args": ["--name", {"inputValue": "name"}, "--status", {"inputValue":
          "status"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\"
          \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def
          status_op(name, status):\n    \"\"\"Dummy method to send pipeline status
          to the configured channel.\n    In this example, it''s STDOUT. In practice,
          it is usually a notification to Slack or email etc\"\"\"\n    print(f\"workflow={name}
          status={status}\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Status
          op'', description=''Dummy method to send pipeline status to the configured
          channel.'')\n_parser.add_argument(\"--name\", dest=\"name\", type=str, required=True,
          default=argparse.SUPPRESS)\n_parser.add_argument(\"--status\", dest=\"status\",
          type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = status_op(**_parsed_args)\n"], "image": "python:3.10-slim-bullseye"}},
          "inputs": [{"name": "name", "type": "String"}, {"name": "status", "type":
          "String"}], "name": "Status op"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"name": "{{workflow.name}}",
          "status": "{{workflow.status}}"}'}
  - name: status-op-2
    container:
      args: [--name, '{{workflow.name}}', --status, Started]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def status_op(name, status):
            """Dummy method to send pipeline status to the configured channel.
            In this example, it's STDOUT. In practice, it is usually a notification to Slack or email etc"""
            print(f"workflow={name} status={status}")

        import argparse
        _parser = argparse.ArgumentParser(prog='Status op', description='Dummy method to send pipeline status to the configured channel.')
        _parser.add_argument("--name", dest="name", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--status", dest="status", type=str, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = status_op(**_parsed_args)
      image: python:3.10-slim-bullseye
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Dummy
          method to send pipeline status to the configured channel.", "implementation":
          {"container": {"args": ["--name", {"inputValue": "name"}, "--status", {"inputValue":
          "status"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\"
          \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def
          status_op(name, status):\n    \"\"\"Dummy method to send pipeline status
          to the configured channel.\n    In this example, it''s STDOUT. In practice,
          it is usually a notification to Slack or email etc\"\"\"\n    print(f\"workflow={name}
          status={status}\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Status
          op'', description=''Dummy method to send pipeline status to the configured
          channel.'')\n_parser.add_argument(\"--name\", dest=\"name\", type=str, required=True,
          default=argparse.SUPPRESS)\n_parser.add_argument(\"--status\", dest=\"status\",
          type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = status_op(**_parsed_args)\n"], "image": "python:3.10-slim-bullseye"}},
          "inputs": [{"name": "name", "type": "String"}, {"name": "status", "type":
          "String"}], "name": "Status op"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"name": "{{workflow.name}}",
          "status": "Started"}'}
  - name: train
    container:
      args: []
      command: [python, train.py, --bucket, '{{inputs.parameters.bucket}}', --processed-train-path,
        '{{inputs.parameters.processed_train_path}}', --param-path, '{{inputs.parameters.param_path}}',
        --model-path, '{{inputs.parameters.model_path}}']
      image: mlops-titanic/pipeline/components/train:1.0
    inputs:
      parameters:
      - {name: bucket}
      - {name: model_path}
      - {name: param_path}
      - {name: processed_train_path}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.22
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"description": "Trains
          the model on processed data.\n", "implementation": {"container": {"command":
          ["python", "train.py", "--bucket", {"inputValue": "bucket"}, "--processed-train-path",
          {"inputValue": "processed_train_path"}, "--param-path", {"inputValue": "param_path"},
          "--model-path", {"inputValue": "model_path"}], "image": "mlops-titanic/pipeline/components/train:1.0"}},
          "inputs": [{"description": "The S3 bucket to store results.", "name": "bucket",
          "type": "String"}, {"description": "The s3 path of processed training data.",
          "name": "processed_train_path", "type": "String"}, {"description": "The
          s3 path of training param file.", "name": "param_path", "type": "String"},
          {"description": "The s3 path to dump the training output.", "name": "model_path",
          "type": "String"}], "name": "Train"}', pipelines.kubeflow.org/component_ref: '{"digest":
          "9b10ee347d50c20b0b150add854ecad0c538c844bf776e1de3f40720fb5f82ab", "url":
          "pipeline/components/train/train.yaml"}', pipelines.kubeflow.org/arguments.parameters: '{"bucket":
          "{{inputs.parameters.bucket}}", "model_path": "{{inputs.parameters.model_path}}",
          "param_path": "{{inputs.parameters.param_path}}", "processed_train_path":
          "{{inputs.parameters.processed_train_path}}"}'}
  arguments:
    parameters:
    - {name: bucket, value: mybucket}
    - {name: param_path, value: param.json}
    - {name: train_path, value: train.csv}
    - {name: test_path, value: test.csv}
    - {name: processed_train_path, value: train.pickle}
    - {name: model_path, value: model.json}
  serviceAccountName: pipeline-runner
  onExit: status-op
